多智能体LLM提示自动生成与优化开源项目调研

近年来，多智能体系统在大语言模型（LLM）提示自动生成与优化领域受到关注。多个项目利用协同机制让多个LLM代理合作迭代生成和优化提示。下文介绍几项代表性开源项目的核心方法、架构、支持模型和功能特点，并说明其是否支持提示自动演化、自我反馈等机制。同时列举相关论文以展示行业最佳实践。

PromptWizard（微软任务自适应提示优化框架）

PromptWizard 是微软提出的离散提示优化框架 ￼。该框架的核心在于让LLM自身迭代地“生成、批判并完善自身的提示和示例”，通过多轮自我反馈实现提示和示例的联合优化 ￼。具体而言，PromptWizard 分为两个阶段：首先迭代优化任务指令（instructions），然后联合优化指令与少样本示例。在此过程中，LLM会根据任务反馈不断改进提示，每次迭代都比上一次效果更好 ￼。框架还引入正负示例和自生成链式思考（CoT）等策略，以增加样本多样性和推理能力。PromptWizard 支持调用OpenAI GPT-3.5/GPT-4（通过API或Azure接口）等模型，并提供配置文件灵活指定模型及参数 ￼ ￼。该项目已开源（MIT协议），由微软研究院维护，Star 数量已达3000+，更新活跃（2024年发布） ￼ ￼。其迭代自反馈机制使其具备完整的提示自动演化能力。

PromptAgent（专家级提示优化）

PromptAgent 是 Xinyuan Wang 等人（ICLR 2024）提出的自动提示优化框架 ￼。它将提示优化视作在蒙特卡洛树搜索（MCTS）中的策略规划问题，通过多个“节点”（提示片段）轮流构建提示，并结合奖励信号来评估质量 ￼。PromptAgent 能够生成质量相当于专家手工设计的提示 ￼。项目支持多种LLM，包括OpenAI的GPT系列、Google的PaLM，以及Hugging Face开源模型（可通过vLLM加速本地推理） ￼。PromptAgent 提供完整的Python实现和示例，用户可通过配置文件指定基础模型和优化过程参数，已被LLM Reasoners库等集成使用。该仓库持续更新（2024年1月ICLR接受，Star数283） ￼ ￼。由于采用MCTS搜索结构，PromptAgent更多依赖外部任务奖励信号进行优化，不是典型的自我反馈循环，但其搜索过程也隐含对提示质量的评估机制。

HMAW（层级多智能体提示优化）

HMAW（Hierarchical Multi-Agent Workflow）由刘雨迟等人提出，是一种层次化的多智能体提示优化流程 ￼。该方法让LLM在层次化流程中自由设计提示：首先由LLM分层生成包含精确指令和详细措辞的提示内容，然后使用该提示对原始查询进行解答 ￼。HMAW 不依赖人工格式限制，也无需额外训练，是真正任务无关的零样本策略 ￼。可以将不同层次视作不同智能体协作完成提示构造和问题解答：下层智能体负责撰写具体指令，顶层智能体给出最终答案。官方代码已开源（MIT协议），采用Python实现，支持调用OpenAI API（例如GPT-3.5）或通过vLLM运行本地模型（如Mixtral） ￼。HMAW框架完全自动化，不含人工反馈组件，依赖多阶段LLM生成实现提示优化。该项目2024年发布，开源星标13，维护较活跃 ￼ ￼。

PROMST（多步骤任务中的提示优化）

PROMST（PRompt Optimization in Multi-Step Tasks）由陈泳超等人（MIT/Harvard，EMNLP 2024）提出 ￼。该框架针对复杂的多步骤任务，将提示优化过程分解为结合人类反馈和启发式搜索的迭代过程 ￼。具体而言，PROMST 定义了一组人工设计的反馈规则，用于分析LLM输出并提出直接改进提示的建议；同时训练一个启发式模型来预测提示性能，辅助高效采样候选提示 ￼。通过反复生成提示候选、应用反馈规则和启发式筛选，PROMST 在多个任务上显著超过手工提示及其他优化方法 ￼。该项目提供完整代码和示例，可复现实验结果，最近版本仍在维护中（2024年2月代码发布，GitHub星标31） ￼ ￼。由于融合了人类反馈规则，PROMST 实现了一种混合的自我评估机制，但核心优化过程依赖规则引导。

AutoPrompt（意图引导的提示校准框架）

AutoPrompt 由 Elad Levy 等人提出，是一个专注于提示校准的开源框架 ￼。该方法从用户给定的初始提示和任务意图出发，通过迭代生成难例并优化提示来提高提示质量 ￼。具体而言，AutoPrompt 自动生成多样化输入样本（尤其是挑战性案例），然后由LLM或人工对这些样本进行注释和执行，接着基于反馈让LLM提出改进后的提示版本 ￼。这一“生成–评估–优化”循环能够显著提高提示的鲁棒性，有效缓解提示敏感性和歧义性问题 ￼。项目提供了全面的实现，包括基于LangChain的集成选项，目前在GitHub上有2500+星标 ￼。AutoPrompt 的迭代校准流程相当于让模型自身反馈提示性能，因此具备完整的自我反馈与提示自动演化能力。

其他代表性论文与最佳实践

相关研究也在探索多智能体提示优化的思路。例如，MultiPrompter（NeurIPS 2023）将提示优化视为多个“提示器”协作生成的博弈，每个提示器依次构建提示片段，从而分解搜索空间 ￼。Multi-Agent System Search（MASS）框架则提出分层搜索：先局部优化提示块，再优化工作流拓扑，最后在全局层面优化提示 ￼。这些工作表明，通过多轮协作和分阶段优化，可以系统地提升提示设计效果 ￼ ￼。此外，PromptWizard等框架暗含自我评估机制让LLM不断反馈和改进；Chain-of-Thought、自我反思（self-reflection）等技术也可视为增强提示可靠性的实践。